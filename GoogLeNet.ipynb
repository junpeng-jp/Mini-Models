{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvfSOYvr8_d1",
        "colab_type": "text"
      },
      "source": [
        "# GoogLeNet v1\n",
        "\n",
        "Paper : [Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAowAX5-8_d2",
        "colab_type": "text"
      },
      "source": [
        "## Difficulties in Training Deep Neural Networks\n",
        "\n",
        "*Deeper Networks are More Prone to Overfitting*\n",
        "\n",
        "- Deeper Networks have more parameters\n",
        "- Greater risk of overfitting, especially when there is a lack of training data\n",
        "- Not the best way forward as it can be expensive and time consuming to obtain quality training data\n",
        "\n",
        "*Dramatic Increase in Computational Requirements with Network Size*\n",
        "\n",
        "- The larger the input size and dimensions, the more computation required\n",
        "- An example provided in the paper is that the existing convolution layers are densely connected, and scale quadratically with the number of kernels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0P2BL9l8_d2",
        "colab_type": "text"
      },
      "source": [
        "## Moving to Sparse Architecture\n",
        "\n",
        "One possible solution suggested is to move towards sparse connections within neural network building blocks. This can help to:\n",
        " - Reduce overfitting as sparse architecture have fewer parameters compared to dense architecture\n",
        " - Save of wasted computation time for connections that end up close to zero\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGusOf1l8_d3",
        "colab_type": "text"
      },
      "source": [
        "## The Inception Module\n",
        "\n",
        "One way of compressing the network is to find layers and kernels in the network that represent largely the same features (i.e. have high correlation). You can then group these filters and use them as the new layer.\n",
        "\n",
        "<div>\n",
        "<img src=\"./assets/GoogLeNet_InceptionModule.png\" width = 800px>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QaLqGJa8_d3",
        "colab_type": "text"
      },
      "source": [
        "## 1x1 Convolution as Compression\n",
        "\n",
        "Drawing inspiration for word embeddings, the Inception modules uses 1x1 convolutions (with ReLU activation) as a tensor compressor that learns an embedding of the previous layers output. \n",
        "\n",
        "This embedding helps to reduce computational requirements of the different convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQA44bl28_d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qybFP4Px8_d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sameConv2d(in_channel, out_channel, kernel_size, stride=1):\n",
        "    return nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding=kernel_size//2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH9F841d8_d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionUnit(torch.nn.Module):\n",
        "    def __init__(self, inChannel, out1x1, reduce3x3, out3x3, reduce5x5, out5x5, poolProj):\n",
        "        super().__init__()\n",
        "        self.feature1_1 = nn.Sequential(\n",
        "            sameConv2d(inChannel, out1x1, kernel_size = 1),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "        self.feature3_3 = nn.Sequential(\n",
        "            sameConv2d(inChannel, reduce3x3, kernel_size = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            sameConv2d(reduce3x3, out3x3, kernel_size = 3),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "        self.feature5_5 = nn.Sequential(\n",
        "            sameConv2d(inChannel, reduce5x5, kernel_size = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            sameConv2d(reduce5x5, out5x5, kernel_size=  5),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "        self.parallelPool = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1, ceil_mode=True),\n",
        "            sameConv2d(inChannel, poolProj, kernel_size = 1),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        out1 = self.feature1_1(input)\n",
        "        out2 = self.feature3_3(input)\n",
        "        out3 = self.feature5_5(input)\n",
        "        out4 = self.parallelPool(input)\n",
        "\n",
        "        return torch.cat([out1, out2, out3, out4], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygnzjyqhbyJ5",
        "colab_type": "text"
      },
      "source": [
        "## Training a Small GoogLeNet\n",
        "\n",
        "As the original GoogLeNet is very deep with multiple pooling layers to digest the 224 x 224 ImageNet training images, the original architecture listed in the paper may not be suitable for the 32 x 32 images in CIFAR-10. For demonstration purposes, a smaller GoogLeNet was build following 2 key principles:\n",
        "\n",
        " - As deeper network layers tend capture features that occupy larger areas of the input, the proportion oof 3x3 and 5x5 filters should increase as the network grows deeper\n",
        " - The same method of 2D Average Pooling to flatten will be used, adjusted for the expected output size of the smaller GoogLeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u689nZW18_eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SmallGoogLeNet(torch.nn.Module):\n",
        "    def __init__(self, nClass):\n",
        "        super().__init__()\n",
        "        self.nClass = nClass\n",
        "        self.conv1 = nn.Sequential(\n",
        "            sameConv2d(3, 64, kernel_size=7, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        )\n",
        "\n",
        "        self.inception2 = nn.Sequential(\n",
        "            InceptionUnit(64, 64, 16, 32, 8, 16, 16),\n",
        "            InceptionUnit(128, 64, 32, 64, 16, 32, 32),\n",
        "            InceptionUnit(192, 48, 56, 112, 32, 64, 32),\n",
        "            InceptionUnit(256, 32, 64, 128, 24, 64, 32),\n",
        "            InceptionUnit(256, 16, 112, 128, 24, 80, 32),\n",
        "            nn.AvgPool2d(kernel_size=8, stride=1, ceil_mode=True),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, self.nClass)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        out = self.conv1(input)\n",
        "        out = self.inception2(out)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPa2vk8G8_eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.nn.init import kaiming_normal_, normal_\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "from helper import training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFi1zHZ58_eG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# seeding the random number generators\n",
        "# ensures some form of determinism in the outputs \n",
        "seed = 2020\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "os.environ['PYTHONHASHSEED']=str(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S9Lt8OL8_eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initWeight(unit):\n",
        "    if isinstance(unit, (torch.nn.Linear, torch.nn.Conv2d)):\n",
        "        kaiming_normal_(unit.weight, nonlinearity='relu')\n",
        "        normal_(unit.bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8E3wCaC8_eM",
        "colab_type": "code",
        "outputId": "33d876f8-259d-4180-c581-fe0c344bbf29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "b431c86d52bb41f0adc54553d2bf4e3f",
            "37bea2125e424ece9cdf04f6df1b0c99",
            "18b9d1f3b93d40e5b7de54541fa523cd",
            "1a510a2dc53a4f72a3eecd4bf442ed51",
            "b6a6bad7404f4904bf1cd5d83b65abf8",
            "bbeb2be0a41e428caff83ed9c63bff20",
            "03184eeb5d494dc8b13568564340eea0",
            "5a610b9c07cc4109bd94f8a54fb59910"
          ]
        }
      },
      "source": [
        "# We will be using the CIFAR-10 dataset\n",
        "trainset = CIFAR10(\n",
        "    root = \"../data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "testset = CIFAR10(\n",
        "    root = \"../data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b431c86d52bb41f0adc54553d2bf4e3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnV3gaCM8_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = training.Trainer(nEpoch=30, logInterval=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxA3sOyF8_eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.addDataloader(\n",
        "    dataloader = DataLoader(\n",
        "        trainset, batch_size=256,\n",
        "        shuffle=True, num_workers=0),\n",
        "    loaderType = 'train')\n",
        "\n",
        "trainer.addDataloader(\n",
        "    dataloader = DataLoader(\n",
        "        testset, batch_size=256, \n",
        "        shuffle=True, num_workers=0),\n",
        "    loaderType = 'test')\n",
        "\n",
        "trainer.addLossFn(nn.CrossEntropyLoss())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE1lnz_d8_eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SmallGoogLeNet(10)\n",
        "model.apply(initWeight)\n",
        "\n",
        "optimizer = Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn7cz5sJ8_eU",
        "colab_type": "code",
        "outputId": "7680da00-5c46-4f43-bdfa-6a921041eece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer.train(model, optimizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [ 1 /30 ]  Batch [ 50  / 196 ]  Loss: 1.9571\n",
            "Epoch [ 1 /30 ]  Batch [ 100 / 196 ]  Loss: 1.9566\n",
            "Epoch [ 1 /30 ]  Batch [ 150 / 196 ]  Loss: 1.7039\n",
            "Epoch [ 1 /30 ]  Batch [ 196 / 196 ]  Loss: 1.8689\n",
            "Epoch [ 2 /30 ]  Batch [ 50  / 196 ]  Loss: 1.7074\n",
            "Epoch [ 2 /30 ]  Batch [ 100 / 196 ]  Loss: 1.5226\n",
            "Epoch [ 2 /30 ]  Batch [ 150 / 196 ]  Loss: 1.5517\n",
            "Epoch [ 2 /30 ]  Batch [ 196 / 196 ]  Loss: 1.5534\n",
            "Epoch [ 3 /30 ]  Batch [ 50  / 196 ]  Loss: 1.4778\n",
            "Epoch [ 3 /30 ]  Batch [ 100 / 196 ]  Loss: 1.5808\n",
            "Epoch [ 3 /30 ]  Batch [ 150 / 196 ]  Loss: 1.5632\n",
            "Epoch [ 3 /30 ]  Batch [ 196 / 196 ]  Loss: 1.3423\n",
            "Epoch [ 4 /30 ]  Batch [ 50  / 196 ]  Loss: 1.3912\n",
            "Epoch [ 4 /30 ]  Batch [ 100 / 196 ]  Loss: 1.4686\n",
            "Epoch [ 4 /30 ]  Batch [ 150 / 196 ]  Loss: 1.4015\n",
            "Epoch [ 4 /30 ]  Batch [ 196 / 196 ]  Loss: 1.3187\n",
            "Epoch [ 5 /30 ]  Batch [ 50  / 196 ]  Loss: 1.2524\n",
            "Epoch [ 5 /30 ]  Batch [ 100 / 196 ]  Loss: 1.4099\n",
            "Epoch [ 5 /30 ]  Batch [ 150 / 196 ]  Loss: 1.4379\n",
            "Epoch [ 5 /30 ]  Batch [ 196 / 196 ]  Loss: 1.3554\n",
            "Epoch [ 6 /30 ]  Batch [ 50  / 196 ]  Loss: 1.3420\n",
            "Epoch [ 6 /30 ]  Batch [ 100 / 196 ]  Loss: 1.1657\n",
            "Epoch [ 6 /30 ]  Batch [ 150 / 196 ]  Loss: 1.2366\n",
            "Epoch [ 6 /30 ]  Batch [ 196 / 196 ]  Loss: 1.2801\n",
            "Epoch [ 7 /30 ]  Batch [ 50  / 196 ]  Loss: 1.1754\n",
            "Epoch [ 7 /30 ]  Batch [ 100 / 196 ]  Loss: 1.1445\n",
            "Epoch [ 7 /30 ]  Batch [ 150 / 196 ]  Loss: 1.1799\n",
            "Epoch [ 7 /30 ]  Batch [ 196 / 196 ]  Loss: 1.3071\n",
            "Epoch [ 8 /30 ]  Batch [ 50  / 196 ]  Loss: 1.1462\n",
            "Epoch [ 8 /30 ]  Batch [ 100 / 196 ]  Loss: 1.1328\n",
            "Epoch [ 8 /30 ]  Batch [ 150 / 196 ]  Loss: 1.0580\n",
            "Epoch [ 8 /30 ]  Batch [ 196 / 196 ]  Loss: 1.1165\n",
            "Epoch [ 9 /30 ]  Batch [ 50  / 196 ]  Loss: 0.9889\n",
            "Epoch [ 9 /30 ]  Batch [ 100 / 196 ]  Loss: 1.0841\n",
            "Epoch [ 9 /30 ]  Batch [ 150 / 196 ]  Loss: 0.8613\n",
            "Epoch [ 9 /30 ]  Batch [ 196 / 196 ]  Loss: 1.0935\n",
            "Epoch [10 /30 ]  Batch [ 50  / 196 ]  Loss: 0.9259\n",
            "Epoch [10 /30 ]  Batch [ 100 / 196 ]  Loss: 0.9128\n",
            "Epoch [10 /30 ]  Batch [ 150 / 196 ]  Loss: 0.9477\n",
            "Epoch [10 /30 ]  Batch [ 196 / 196 ]  Loss: 0.9328\n",
            "Epoch [11 /30 ]  Batch [ 50  / 196 ]  Loss: 0.9586\n",
            "Epoch [11 /30 ]  Batch [ 100 / 196 ]  Loss: 0.8411\n",
            "Epoch [11 /30 ]  Batch [ 150 / 196 ]  Loss: 1.0596\n",
            "Epoch [11 /30 ]  Batch [ 196 / 196 ]  Loss: 0.9935\n",
            "Epoch [12 /30 ]  Batch [ 50  / 196 ]  Loss: 0.8739\n",
            "Epoch [12 /30 ]  Batch [ 100 / 196 ]  Loss: 0.8193\n",
            "Epoch [12 /30 ]  Batch [ 150 / 196 ]  Loss: 0.8402\n",
            "Epoch [12 /30 ]  Batch [ 196 / 196 ]  Loss: 0.8734\n",
            "Epoch [13 /30 ]  Batch [ 50  / 196 ]  Loss: 0.8433\n",
            "Epoch [13 /30 ]  Batch [ 100 / 196 ]  Loss: 0.8104\n",
            "Epoch [13 /30 ]  Batch [ 150 / 196 ]  Loss: 0.8679\n",
            "Epoch [13 /30 ]  Batch [ 196 / 196 ]  Loss: 0.8378\n",
            "Epoch [14 /30 ]  Batch [ 50  / 196 ]  Loss: 0.8090\n",
            "Epoch [14 /30 ]  Batch [ 100 / 196 ]  Loss: 0.6966\n",
            "Epoch [14 /30 ]  Batch [ 150 / 196 ]  Loss: 0.7383\n",
            "Epoch [14 /30 ]  Batch [ 196 / 196 ]  Loss: 0.7807\n",
            "Epoch [15 /30 ]  Batch [ 50  / 196 ]  Loss: 0.8807\n",
            "Epoch [15 /30 ]  Batch [ 100 / 196 ]  Loss: 0.7660\n",
            "Epoch [15 /30 ]  Batch [ 150 / 196 ]  Loss: 0.7129\n",
            "Epoch [15 /30 ]  Batch [ 196 / 196 ]  Loss: 0.8734\n",
            "Epoch [16 /30 ]  Batch [ 50  / 196 ]  Loss: 0.7048\n",
            "Epoch [16 /30 ]  Batch [ 100 / 196 ]  Loss: 0.7856\n",
            "Epoch [16 /30 ]  Batch [ 150 / 196 ]  Loss: 0.8994\n",
            "Epoch [16 /30 ]  Batch [ 196 / 196 ]  Loss: 0.5989\n",
            "Epoch [17 /30 ]  Batch [ 50  / 196 ]  Loss: 0.6776\n",
            "Epoch [17 /30 ]  Batch [ 100 / 196 ]  Loss: 0.7941\n",
            "Epoch [17 /30 ]  Batch [ 150 / 196 ]  Loss: 0.6773\n",
            "Epoch [17 /30 ]  Batch [ 196 / 196 ]  Loss: 0.7818\n",
            "Epoch [18 /30 ]  Batch [ 50  / 196 ]  Loss: 0.5380\n",
            "Epoch [18 /30 ]  Batch [ 100 / 196 ]  Loss: 0.7251\n",
            "Epoch [18 /30 ]  Batch [ 150 / 196 ]  Loss: 0.7443\n",
            "Epoch [18 /30 ]  Batch [ 196 / 196 ]  Loss: 0.7380\n",
            "Epoch [19 /30 ]  Batch [ 50  / 196 ]  Loss: 0.5403\n",
            "Epoch [19 /30 ]  Batch [ 100 / 196 ]  Loss: 0.6135\n",
            "Epoch [19 /30 ]  Batch [ 150 / 196 ]  Loss: 0.6008\n",
            "Epoch [19 /30 ]  Batch [ 196 / 196 ]  Loss: 0.5967\n",
            "Epoch [20 /30 ]  Batch [ 50  / 196 ]  Loss: 0.5487\n",
            "Epoch [20 /30 ]  Batch [ 100 / 196 ]  Loss: 0.6590\n",
            "Epoch [20 /30 ]  Batch [ 150 / 196 ]  Loss: 0.5458\n",
            "Epoch [20 /30 ]  Batch [ 196 / 196 ]  Loss: 0.6158\n",
            "Epoch [21 /30 ]  Batch [ 50  / 196 ]  Loss: 0.4724\n",
            "Epoch [21 /30 ]  Batch [ 100 / 196 ]  Loss: 0.5091\n",
            "Epoch [21 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4819\n",
            "Epoch [21 /30 ]  Batch [ 196 / 196 ]  Loss: 0.7246\n",
            "Epoch [22 /30 ]  Batch [ 50  / 196 ]  Loss: 0.4945\n",
            "Epoch [22 /30 ]  Batch [ 100 / 196 ]  Loss: 0.6453\n",
            "Epoch [22 /30 ]  Batch [ 150 / 196 ]  Loss: 0.5569\n",
            "Epoch [22 /30 ]  Batch [ 196 / 196 ]  Loss: 0.5901\n",
            "Epoch [23 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3813\n",
            "Epoch [23 /30 ]  Batch [ 100 / 196 ]  Loss: 0.5004\n",
            "Epoch [23 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4768\n",
            "Epoch [23 /30 ]  Batch [ 196 / 196 ]  Loss: 0.4556\n",
            "Epoch [24 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3603\n",
            "Epoch [24 /30 ]  Batch [ 100 / 196 ]  Loss: 0.5201\n",
            "Epoch [24 /30 ]  Batch [ 150 / 196 ]  Loss: 0.5289\n",
            "Epoch [24 /30 ]  Batch [ 196 / 196 ]  Loss: 0.4349\n",
            "Epoch [25 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3967\n",
            "Epoch [25 /30 ]  Batch [ 100 / 196 ]  Loss: 0.3961\n",
            "Epoch [25 /30 ]  Batch [ 150 / 196 ]  Loss: 0.3656\n",
            "Epoch [25 /30 ]  Batch [ 196 / 196 ]  Loss: 0.5332\n",
            "Epoch [26 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3266\n",
            "Epoch [26 /30 ]  Batch [ 100 / 196 ]  Loss: 0.3476\n",
            "Epoch [26 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4540\n",
            "Epoch [26 /30 ]  Batch [ 196 / 196 ]  Loss: 0.4262\n",
            "Epoch [27 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3022\n",
            "Epoch [27 /30 ]  Batch [ 100 / 196 ]  Loss: 0.3130\n",
            "Epoch [27 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4139\n",
            "Epoch [27 /30 ]  Batch [ 196 / 196 ]  Loss: 0.3707\n",
            "Epoch [28 /30 ]  Batch [ 50  / 196 ]  Loss: 0.2988\n",
            "Epoch [28 /30 ]  Batch [ 100 / 196 ]  Loss: 0.2993\n",
            "Epoch [28 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4543\n",
            "Epoch [28 /30 ]  Batch [ 196 / 196 ]  Loss: 0.2167\n",
            "Epoch [29 /30 ]  Batch [ 50  / 196 ]  Loss: 0.3170\n",
            "Epoch [29 /30 ]  Batch [ 100 / 196 ]  Loss: 0.2860\n",
            "Epoch [29 /30 ]  Batch [ 150 / 196 ]  Loss: 0.4301\n",
            "Epoch [29 /30 ]  Batch [ 196 / 196 ]  Loss: 0.2212\n",
            "Epoch [30 /30 ]  Batch [ 50  / 196 ]  Loss: 0.2845\n",
            "Epoch [30 /30 ]  Batch [ 100 / 196 ]  Loss: 0.3091\n",
            "Epoch [30 /30 ]  Batch [ 150 / 196 ]  Loss: 0.3055\n",
            "Epoch [30 /30 ]  Batch [ 196 / 196 ]  Loss: 0.2347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt7PyMtJ8_eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.test(model, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJHOG1YW8_eY",
        "colab_type": "code",
        "outputId": "e88cbf5c-201e-410f-d091-eeea3e00ad38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Accuracy\n",
        "torch.true_divide(torch.diagonal(trainer.confMatrix).sum(), trainer.confMatrix.sum()).item()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7168999910354614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQzH0RwP-u74",
        "colab_type": "code",
        "outputId": "ed69b8ee-a0f6-499f-c1ed-4ab6ee53dcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "trainer.confMatrix"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[834,  26,  91,  34,  33,  21,  11,  20, 104,  41],\n",
              "        [ 15, 801,   2,   8,   1,   5,   0,   1,  17,  52],\n",
              "        [ 15,   0, 489,  25,  37,  21,  13,   9,   8,   2],\n",
              "        [ 25,  11,  73, 529,  36, 183,  55,  24,  12,  17],\n",
              "        [ 12,   1,  90,  70, 645,  34,  28,  30,   2,   3],\n",
              "        [  3,   4,  44, 121,  12, 533,  13,  22,   3,   2],\n",
              "        [ 15,  10, 107,  79,  67,  58, 829,  10,   6,   5],\n",
              "        [ 12,   7,  75,  90, 152, 126,  29, 869,   7,  27],\n",
              "        [ 38,  24,  13,  19,  11,   7,  12,   2, 808,  19],\n",
              "        [ 31, 116,  16,  25,   6,  12,  10,  13,  33, 832]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQ18f6zCMHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python37464bitalyxconda5e12d191f71047d98c62eaab66bc9bd3",
      "display_name": "Python 3.7.4 64-bit ('alyx': conda)"
    },
    "colab": {
      "name": "GoogLeNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b431c86d52bb41f0adc54553d2bf4e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37bea2125e424ece9cdf04f6df1b0c99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18b9d1f3b93d40e5b7de54541fa523cd",
              "IPY_MODEL_1a510a2dc53a4f72a3eecd4bf442ed51"
            ]
          }
        },
        "37bea2125e424ece9cdf04f6df1b0c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18b9d1f3b93d40e5b7de54541fa523cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6a6bad7404f4904bf1cd5d83b65abf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbeb2be0a41e428caff83ed9c63bff20"
          }
        },
        "1a510a2dc53a4f72a3eecd4bf442ed51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03184eeb5d494dc8b13568564340eea0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 16951175.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a610b9c07cc4109bd94f8a54fb59910"
          }
        },
        "b6a6bad7404f4904bf1cd5d83b65abf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbeb2be0a41e428caff83ed9c63bff20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03184eeb5d494dc8b13568564340eea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a610b9c07cc4109bd94f8a54fb59910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}